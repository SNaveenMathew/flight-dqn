{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section: Initialization\n",
    "\n",
    "- setting values for global variables\n",
    "- loading required packages\n",
    "- reading files\n",
    "- setting up logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is for supervised learning using previous state to predict current action\n",
    "# Code from gym-flight to be reused as much as possible\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../gym-flight/')\n",
    "import gym_flight\n",
    "from gym_flight.utils.numpy_util import Sparse3dArray\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from continuous import *\n",
    "from full3d_util import get_last_ts_data, create_space_ts, get_range_df, get_action_continuous, get_env_action_aircraft, get_X_Y, fix_XY, unlist, bind, train_test_split\n",
    "import multiprocessing as mp\n",
    "import pickle\n",
    "splits = mp.cpu_count() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    filename='log.txt',\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s.%(msecs)03d %(levelname)s %(module)s - %(funcName)s: %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    ")\n",
    "x_length = 100\n",
    "y_length = 100\n",
    "z_length = 100\n",
    "ts_range = 5\n",
    "time_dim = 1\n",
    "state_dim = [x_length, y_length, z_length]\n",
    "learning_rate = 0.025\n",
    "flight_data_path = \"../gym-flight/data/processed_jfk.csv\"\n",
    "dtype_dict = {\"id\": str, \"ts\": np.int16, \"lat\": np.float32, \"lon\": np.float32, \"altitude\": np.float32, \"speed\": np.float32, \"x\": np.int16, \"y\": np.int16, \"z\": np.int16, \"is_landing\": np.int8}\n",
    "flight_data = pd.read_csv(flight_data_path, dtype = dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete 100 * 100 * 100 space for each timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_range_df_with_params(rng):\n",
    "    return get_range_df(rng, flight_data, x_length, y_length, z_length, ts_range)\n",
    "\n",
    "# Space for a timestamp remains the same. Only the action is continuous\n",
    "if os.path.isfile('ts_full3d_space.bin'):\n",
    "    space_X = pickle.load(open('ts_full3d_space.bin', 'rb'))\n",
    "else:\n",
    "    p = mp.Pool(processes = splits)\n",
    "    # Arranging in reverse order to speed up computation\n",
    "    rng = list(reversed(range(min(flight_data['ts']), max(flight_data['ts']) + 1)))\n",
    "    split_rng = np.array_split(rng, splits)\n",
    "    pool_results = p.map(get_range_df_with_params, split_rng)\n",
    "    p.close()\n",
    "    p.join()\n",
    "    space_X = np.concatenate(pool_results, axis = 0)\n",
    "    space_X = np.flip(space_X, axis = 0)\n",
    "    pickle.dump(space_X, open(\"ts_full3d_space.bin\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action\n",
    "\n",
    "Coding action as set of 3 continuous variables:\n",
    "\n",
    "- Change in ground speed\n",
    "- Change in altitude\n",
    "- Change in heading (azimuth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('Y_train_full3d_space_continuous_action.bin'):\n",
    "    X_train = pickle.load(open('X_train_full3d_space_multiclass_action.bin', 'rb'))\n",
    "    Y_train = pickle.load(open('Y_train_full3d_space_continuous_action.bin', 'rb'))\n",
    "    X_test = pickle.load(open('X_test_full3d_space_multiclass_action.bin', 'rb'))\n",
    "    Y_test = pickle.load(open('Y_test_full3d_space_continuous_action.bin', 'rb'))\n",
    "else:\n",
    "    uniq_id = flight_data['id'].unique()\n",
    "    #     uniq_id = uniq_id[:50]\n",
    "    XY = get_X_Y(uniq_id, flight_data, x_length, y_length, z_length, space_X, discrete_action = False)\n",
    "    X, Y = fix_XY(XY)\n",
    "    X_train, Y_train, X_test, Y_test = train_test_split(X, Y)\n",
    "    pickle.dump(X_train, open(\"X_train_full3d_space_multiclass_action.bin\", \"wb\"))\n",
    "    pickle.dump(Y_train, open(\"Y_train_full3d_space_continuous_action.bin\", \"wb\"))\n",
    "    pickle.dump(X_test, open(\"X_test_full3d_space_multiclass_action.bin\", \"wb\"))\n",
    "    pickle.dump(Y_test, open(\"Y_test_full3d_space_continuous_action.bin\", \"wb\"))\n",
    "\n",
    "train_ac_index = [len(X[0]) for X in X_train]\n",
    "test_ac_index = [len(X[0]) for X in X_test]\n",
    "X_train = unlist(unlist(X_train))\n",
    "Y_train = bind(unlist(Y_train))\n",
    "Y_train = Y_train.astype(np.float16)\n",
    "\n",
    "X_test = unlist(unlist(X_test))\n",
    "Y_test = bind(unlist(Y_test))\n",
    "Y_test = Y_test.astype(np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restricting data to 1500 ft/min descent rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494709\n",
      "(494709, 3)\n",
      "203621\n",
      "(203621, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = [X_train[i] for i, y in enumerate(Y_train) if (y[1] >= -1500 and y[1] <= 1500)]\n",
    "Y_train = Y_train[(Y_train[:, 1] >= -1500) & (Y_train[:, 1] <= 1500), :]\n",
    "print(len(X_train))\n",
    "print(Y_train.shape)\n",
    "\n",
    "X_test = [X_test[i] for i, y in enumerate(Y_test) if (y[1] >= -1500 and y[1] <= 1500)]\n",
    "Y_test = Y_test[(Y_test[:, 1] >= -1500) & (Y_test[:, 1] <= 1500), :]\n",
    "print(len(X_test))\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting minimum and maxmimum values for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_min = np.min(Y_train, axis = 0)\n",
    "test_min = np.min(Y_test, axis = 0)\n",
    "min_array = np.array([min(train_min[i], test_min[i]) for i in range(3)])\n",
    "train_min = np.min(Y_train, axis = 0)\n",
    "test_min = np.min(Y_test, axis = 0)\n",
    "min_array = np.array([min(train_min[i], test_min[i]) for i in range(3)])\n",
    "\n",
    "train_max = np.max(Y_train, axis = 0)\n",
    "test_max = np.max(Y_test, axis = 0)\n",
    "max_array = np.array([max(train_max[i], test_max[i]) for i in range(3)])\n",
    "train_max = np.max(Y_train, axis = 0)\n",
    "test_max = np.max(Y_test, axis = 0)\n",
    "max_array = np.array([max(train_max[i], test_max[i]) for i in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = (Y_train-min_array)/(max_array - min_array)\n",
    "Y_test = (Y_test-min_array)/(max_array - min_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section on CNN, prediction, training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/atc/notebooks/flight-dqn/continuous.py:15: conv3d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv3d instead.\n",
      "WARNING:tensorflow:From /home/atc/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/atc/notebooks/flight-dqn/continuous.py:24: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/atc/notebooks/flight-dqn/continuous.py:27: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/atc/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "state_dim = [x_length, y_length, z_length]\n",
    "cnn = CNN_continuous(state_dim, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "# unique_ts = flight_data['ts'].unique()\n",
    "# for i in range(len(unique_ts)):\n",
    "#     train_X.append(create_space_ts(ts = unique_ts.iloc[i], flight_data = flight_data, x_length = x_length, y_length = y_length, z_length = z_length, ts_range = ts_range))\n",
    "\n",
    "# Row binding all the arrays\n",
    "# train_X = np.concatenate(train_X, axis = 0)\n",
    "perc = 0\n",
    "epochs = 1\n",
    "batch_size = 128\n",
    "num_batches = len(X_train)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1:  mini-batch 1/3864:  Train loss: 0.00522669916972518  Test loss: 745179.6875 \n",
      "Epoch: 1/1:  mini-batch 2/3864:  Train loss: 753682.6875  Test loss: 0.9753214716911316 \n",
      "Epoch: 1/1:  mini-batch 3/3864:  Train loss: 1.0503935813903809  Test loss: 2.972888946533203 \n",
      "Epoch: 1/1:  mini-batch 4/3864:  Train loss: 3.1596667766571045  Test loss: 0.7117863297462463 \n",
      "Epoch: 1/1:  mini-batch 5/3864:  Train loss: 0.5214526057243347  Test loss: 1.276354432106018 \n",
      "Epoch: 1/1:  mini-batch 6/3864:  Train loss: 1.0747840404510498  Test loss: 0.08401143550872803 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-452d4f5d059e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtrain_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_completed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_completed\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtrain_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_completed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_completed\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Runs out of memory while evaluating on the complete test set. Only batch_size used for evaluating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# This step should be randomized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebooks/flight-dqn/continuous.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(sess, cnn, state, action)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Function for training the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate_to_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebooks/flight-dqn/continuous.py\u001b[0m in \u001b[0;36mstate_to_frame\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# If it is a stacked state (i.e. list of Sparse3dArray)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparse3dArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate_to_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;31m# If it is a list of stacked state (i.e. list of list of Sparse3dArray)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparse3dArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebooks/flight-dqn/continuous.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# If it is a stacked state (i.e. list of Sparse3dArray)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparse3dArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate_to_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;31m# If it is a list of stacked state (i.e. list of list of Sparse3dArray)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparse3dArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/notebooks/flight-dqn/continuous.py\u001b[0m in \u001b[0;36mstate_to_frame\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mstate_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# If it is a stacked state (i.e. list of Sparse3dArray)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "completed = 0\n",
    "epoch_train_losses = []\n",
    "epoch_test_losses = []\n",
    "ended = False\n",
    "epoch = 0\n",
    "sess = tf.Session()\n",
    "# Initialize variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "while (epoch < epochs) and not(ended):\n",
    "    completed = int(epoch * 100/epochs)\n",
    "    if completed >= perc:\n",
    "        logging.info(str(perc) + \" % completed\")\n",
    "        perc = int(epoch * 100/epochs)\n",
    "\n",
    "    batch_completed = 0\n",
    "    mini_batch = 1\n",
    "    mini_batch_train_losses = []\n",
    "    mini_batch_test_losses = []\n",
    "    while batch_completed < (len(X_train) - batch_size):\n",
    "        train_X = X_train[batch_completed:(batch_completed + batch_size)]\n",
    "        train_Y = Y_train[batch_completed:(batch_completed + batch_size)]\n",
    "        loss = train(sess, cnn, train_X, train_Y)\n",
    "        # Runs out of memory while evaluating on the complete test set. Only batch_size used for evaluating\n",
    "        # This step should be randomized\n",
    "        test_loss = get_loss(sess, cnn, X_test[0:batch_size], Y_test[0:batch_size])\n",
    "        print('Epoch: {}/{}: '.format(epoch+1, epochs), 'mini-batch {}/{}: '.format(mini_batch, num_batches), \"Train loss: {} \".format(loss), \"Test loss: {} \".format(test_loss))\n",
    "        batch_completed += batch_size\n",
    "        mini_batch += 1\n",
    "        mini_batch_train_losses.append(loss)\n",
    "        mini_batch_test_losses.append(test_loss)\n",
    "    epoch_train_losses.append(sum(mini_batch_train_losses)/len(mini_batch_train_losses))\n",
    "    epoch_test_losses.append(sum(mini_batch_test_losses)/len(mini_batch_test_losses))\n",
    "    # Early stopping check (callback should be used instead):\n",
    "    if (epoch > 0) and (epoch_test_losses[epoch] > epoch_test_losses[epoch - 1]):\n",
    "        saver.save(sess, \"supervised_CNN_full3d_continuous\")\n",
    "        ended = True\n",
    "\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.save(sess, \"supervised_CNN_full3d_continuous\")\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
